{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankability Predicting Sensitivity\n",
    "### March Madness Dataset\n",
    "\n",
    "Look for new features:</br>\n",
    "Existing features:</br>\n",
    "Diversity of P metrics</br>\n",
    "Graph measures of tournament matrix as Lapacian</br>\n",
    "Eigenvalues of tournament matrix</br>\n",
    "\n",
    "Datasets:</br>\n",
    "\n",
    "Lichess:</br> API: https://berserk.readthedocs.io/en/master/ </br> Look for tournaments, grab games played in that time frame and create D matricies</br> API is pretty simple we just need to build a scraping script.</br>\n",
    "\n",
    "Sumo: Data: https://data.world/cervus/sumo-results </br> It's literally just CSVs, so grab to PANDAS and build D from columns Bad news: Have to make an account to download data :( /s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# We need to include the path to pyrankability. This could be different for Tim, but altneratively he could point to your copy\n",
    "sys.path.insert(0,\"/disk/home/amy/rankability_toolbox_dev\")\n",
    "import pyrankability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"/disk/home/amy/sensitivity_study/src\")\n",
    "from sensitivity_tests import *\n",
    "from utilities import *\n",
    "from base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games={}\n",
    "years = [\"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\"]\n",
    "for year in years:\n",
    "    games[year] = read_data('../data/%steams.txt'%year,'../data/%sgames.txt'%year,'../data/%sMadnessTeams.txt'%year)\n",
    "games[year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to future self: Parameters from FODS paper but might need to be optimized\n",
    "direct_thres = 2\n",
    "spread_thres = 2\n",
    "weight_indirect = 0.5\n",
    "Ds = {}\n",
    "fracs = [0.5, 0.75, 1.] # 25% of total data added per step\n",
    "#fracs = [0.64, 0.8, 1.] # 25% of current data added per step\n",
    "pairs = list(zip(fracs[:-1], fracs[1:]))\n",
    "pair_to_predict = pairs[0]\n",
    "\n",
    "for year in games.keys():\n",
    "    print(year)\n",
    "    Ds[year] = {}\n",
    "    madness_teams = np.unique(list(games[year].team1_name.loc[games[year].team1_madness == 1]) + list(games[year].team2_name.loc[games[year].team2_madness == 1]))\n",
    "    game_list = list(games[year].index)\n",
    "    \n",
    "    game_df = pd.DataFrame({\"team1_name\":games[year]['team1_name'],\n",
    "                            \"team1_score\":games[year]['points1'],\n",
    "                            \"team1_H_A_N\": games[year]['H_A_N1'],\n",
    "                            \"team2_name\":games[year]['team2_name'],\n",
    "                            \"team2_score\":games[year]['points2'],\n",
    "                            \"team2_H_A_N\": games[year]['H_A_N1'],\n",
    "                            \"date\": games[year]['date']\n",
    "                           }).sort_values(by='date').drop('date',axis=1)\n",
    "    for frac in fracs:\n",
    "        upper = int(len(game_df)*frac)\n",
    "        game_df_sample = game_df.iloc[:upper,:]\n",
    "        map_func = lambda linked: support_map_vectorized_direct_indirect_weighted(linked,direct_thres=direct_thres,spread_thres=spread_thres,weight_indirect=weight_indirect)\n",
    "        Ds[year][frac] = pyrankability.construct.V_count_vectorized(game_df_sample,map_func).loc[madness_teams,madness_teams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = {}\n",
    "taus = {}\n",
    "results = pd.DataFrame(columns=pairs+[\"Year\"]).set_index(\"Year\")\n",
    "\n",
    "for year in games.keys():\n",
    "    rankings[year] = []\n",
    "    taus[year] = {}\n",
    "    data = []\n",
    "    for i in range(len(pairs)):\n",
    "        pair = pairs[i]\n",
    "        D1 = Ds[year][pair[0]]\n",
    "        D2 = Ds[year][pair[1]]\n",
    "        ranking1 = MasseyRankingAlgorithm().rank(D1.fillna(0).values)\n",
    "        ranking2 = MasseyRankingAlgorithm().rank(D2.fillna(0).values)\n",
    "        rankings[year].append((ranking1,ranking2))\n",
    "        ranking1, ranking2 = rankings[year][i]\n",
    "        taus[year][pair] = kendall_tau(ranking1,ranking2)\n",
    "        data.append(taus[year][pair])\n",
    "    results = results.append(pd.Series(data,index=results.columns,name=year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: what do the contents of this matrix mean??\n",
    "# Ds['2018'][1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details = []\n",
    "def get_rankability_results(n_restarts=250):\n",
    "    df_ks = []\n",
    "    df_years = []\n",
    "    df_fracs = []\n",
    "    df_p_stats = {}\n",
    "    for year in games.keys():\n",
    "        print(year)\n",
    "        for pair in pairs:\n",
    "            D = Ds[year][pair[0]].fillna(0)\n",
    "            #C = pyrankability.construct.C_count(D,0)\n",
    "            k,details = pyrankability.rank.solve(D,method='lop', num_random_restarts=n_restarts, lazy=False, cont=True)\n",
    "            p_stats = get_P_stats(details[\"P\"])\n",
    "            for name, val in p_stats.items():\n",
    "                if name not in df_p_stats:\n",
    "                    df_p_stats[name] = []\n",
    "                df_p_stats[name].append(val)\n",
    "            df_ks.append(k)\n",
    "            df_years.append(year)\n",
    "            df_fracs.append(pair[0])\n",
    "            df_details.append(details)\n",
    "\n",
    "    results_temp = {\"k\":df_ks,\"Year\":df_years,\"Fraction\":df_fracs}\n",
    "    for key, val in df_p_stats.items():\n",
    "        if key in results_temp:\n",
    "            raise ValueError(\"Duplicate column name! Fix collision before moving on!\")\n",
    "        results_temp[key] = val\n",
    "\n",
    "    return pd.DataFrame(results_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankability_results = get_rankability_results()\n",
    "rankability_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_corr = rankability_results.loc[rankability_results.Fraction==pair_to_predict[0]].set_index('Year').join(results)\n",
    "for_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(for_corr['k'],for_corr[pair_to_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    'Year',\n",
    "    '# X* frac',\n",
    "    'k',\n",
    "    '# X* frac top 40',\n",
    "    'kendall_w',\n",
    "    'p_lowerbound',\n",
    "    'max_L2_dist',\n",
    "    'mean_L2_dist',\n",
    "    'min_tau',\n",
    "    'mean_tau',\n",
    "    'Pair'\n",
    "]\n",
    "\n",
    "all_score_df = pd.DataFrame(columns=col_names)\n",
    "\n",
    "c=0\n",
    "for year in games.keys():\n",
    "    print(year)\n",
    "    for pair in pairs:\n",
    "        V = Ds[year][pair_to_predict[0]]\n",
    "        rresults = rankability_results.iloc[c,:]\n",
    "        k = rresults['k']\n",
    "        details = df_details[c]\n",
    "        x = pd.DataFrame(details['x'],index=V.index,columns=V.columns)\n",
    "        r = x.sum(axis=0)\n",
    "        order = np.argsort(r)\n",
    "        xstar = x.iloc[order,:].iloc[:,order]\n",
    "        xstar.loc[:,:] = pyrankability.common.threshold_x(xstar.values)\n",
    "        inxs = np.triu_indices(len(xstar),k=1)\n",
    "        xstar_upper = xstar.values[inxs[0],inxs[1]]\n",
    "        nfrac_upper = sum((xstar_upper > 0) & (xstar_upper < 1))\n",
    "        flat_frac = ((xstar > 0) & (xstar < 1)).sum(axis=0)\n",
    "        nfrac_top_40 = flat_frac.iloc[:40].sum()\n",
    "        entry_data = [\n",
    "            year,\n",
    "            nfrac_upper*2,\n",
    "            k,\n",
    "            nfrac_top_40,\n",
    "            rresults[\"kendall_w\"],\n",
    "            rresults[\"p_lowerbound\"],\n",
    "            rresults[\"max_L2_dist\"],\n",
    "            rresults[\"mean_L2_dist\"],\n",
    "            rresults[\"min_tau\"],\n",
    "            rresults[\"mean_tau\"],\n",
    "            pair\n",
    "        ]\n",
    "        entry = pd.Series(entry_data,col_names,name=c)\n",
    "        c+=1\n",
    "        all_score_df = all_score_df.append(entry)\n",
    "all_score_df.set_index(\"Year\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score_df = all_score_df.loc[all_score_df.Pair == pair_to_predict].drop('Pair',axis=1).join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save all_score_df for easy reuse\n",
    "# TODO: add function to reload all_score_df from saved file\n",
    "all_score_df.to_csv(\"all_score_df.csv\")\n",
    "\n",
    "# all_score_df = pd.read_csv(\"all_score_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_score_df.columns:\n",
    "    if col not in pairs:\n",
    "        all_score_df.plot.scatter(col, pair_to_predict, title=\"Final Sensitivity vs \" + col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "all_feature_cols = [c for c in all_score_df.columns if c not in pairs]\n",
    "\n",
    "def evaluate(df,pred_col=pair_to_predict,feature_cols=all_feature_cols,model=DummyRegressor(),param_grid={}):\n",
    "    # fill in evaluat\n",
    "    loo = LeaveOneOut()\n",
    "    y = df[pred_col]\n",
    "    X = df[feature_cols]\n",
    "    \n",
    "    grid = GridSearchCV(model,param_grid,refit=True,verbose=2,n_jobs=-1)\n",
    "    scores = cross_val_score(grid, X, y, scoring=\"neg_mean_absolute_error\", cv=loo, n_jobs=1)\n",
    "    return pd.Series([len(scores),np.mean(np.abs(scores)),np.std(scores)],index=[\"Folds\",\"MAE\",\"STD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(all_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(all_score_df,model=SVR(gamma='scale'),param_grid = {'C': [0.1,1,10,100], 'epsilon': [0.1,0.5,1],'kernel': ['linear', 'rbf']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
