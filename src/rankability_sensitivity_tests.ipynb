{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensitivity_tests import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from gurobipy import *\n",
    "setParam(\"OutputFlag\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Algorithms\n",
    "colley = ColleyRankingAlgorithm()\n",
    "massey = MasseyRankingAlgorithm()\n",
    "lop_alg = LOPRankingAlgorithm()\n",
    "\n",
    "# Rankability Metric\n",
    "rankability_metrics = [\n",
    "    KendallWMetric(),\n",
    "    MeanTauMetric(),\n",
    "    L2DifferenceMetric(strategy=\"max\"),\n",
    "    L2DifferenceMetric(strategy=\"mean\")\n",
    "]\n",
    "\n",
    "metric_names = [\"KendallW\", \"MeanTau\", \"L2DifferenceMax\", \"L2DifferenceMean\"]\n",
    "\n",
    "# Noise Generator\n",
    "swapNoiseGen = SwapNoise(noisePercentage=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELO_var = [1, 5] + [x for x in range(10, 201, 10)]\n",
    "n_instances = 300\n",
    "n_trials = 30\n",
    "n_items = 16\n",
    "\n",
    "lop_taus = []\n",
    "lop_rs = {}\n",
    "massey_taus = []\n",
    "massey_rs = {}\n",
    "colley_taus = []\n",
    "colley_rs = {}\n",
    "\n",
    "for name in metric_names:\n",
    "    lop_rs[name] = []\n",
    "    massey_rs[name] = []\n",
    "    colley_rs[name] = []\n",
    "\n",
    "for var in tqdm(ELO_var):\n",
    "    data_source = SynthELOTournamentSource(16, n_games=30, comp_var=var)\n",
    "    for instance_idx in range(n_instances):\n",
    "        inst = ProblemInstance(data_source, swapNoiseGen)\n",
    "        rs, taus = inst.get_sensitivity(lop_alg, rankability_metrics, n_trials=n_trials, progress_bar=False)\n",
    "        lop_taus.extend(taus)\n",
    "        for r_idx in range(len(rs)):\n",
    "            lop_rs[metric_names[r_idx]].extend([rs[r_idx]]*n_trials)\n",
    "        rs, taus = inst.get_sensitivity(massey, rankability_metrics, n_trials=n_trials, progress_bar=False)\n",
    "        massey_taus.extend(taus)\n",
    "        for r_idx in range(len(rs)):\n",
    "            massey_rs[metric_names[r_idx]].extend([rs[r_idx]]*n_trials)\n",
    "        rs, taus = inst.get_sensitivity(colley, rankability_metrics, n_trials=n_trials, progress_bar=False)\n",
    "        colley_taus.extend(taus)\n",
    "        for r_idx in range(len(rs)):\n",
    "            colley_rs[metric_names[r_idx]].extend([rs[r_idx]]*n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_taus(rankability_vals, taus, method_name, scatter_alpha=0.01, histogram_bins=30, save_dir=\"rankability_figures\"):\n",
    "    # Create directory for saving if specified\n",
    "    saving = False\n",
    "    if save_dir is not None and save_dir != \"\":\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        saving = True\n",
    "    \n",
    "    # Plot scatter plot\n",
    "    plt.scatter(rankability_vals, taus, alpha=scatter_alpha)\n",
    "    title = \"%s Sensitivity Scatter\" % method_name\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Rankability')\n",
    "    plt.xlim(0.0, 1.0)\n",
    "    plt.ylabel('Tau')\n",
    "    plt.ylim(-1.0, 1.0)\n",
    "    if saving:\n",
    "        save_path = os.path.join(save_dir, title.replace(\" \", \"_\") + \".png\")\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 2D Histogram\n",
    "    plt.hist2d(rankability_vals, taus, bins=histogram_bins, range=[[0.0, 1.0], [-1.0, 1.0]])\n",
    "    title = \"%s Sensitivity Histogram\" % method_name\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Rankability')\n",
    "    plt.ylabel('Tau')\n",
    "    if saving:\n",
    "        save_path = os.path.join(save_dir, title.replace(\" \", \"_\") + \".png\")\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name in metric_names:\n",
    "    plot_taus(lop_rs[metric_name], lop_taus, \"LOP (%s)\" % metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name in metric_names:\n",
    "    plot_taus(massey_rs[metric_name], lop_taus, \"Massey (%s)\" % metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name in metric_names:\n",
    "    plot_taus(colley_rs[metric_name], lop_taus, \"Colley (%s)\" % metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_taus = lop_taus + massey_taus + colley_taus\n",
    "for metric_name in metric_names:\n",
    "    combined_rs = lop_rs[metric_name] + massey_rs[metric_name] + colley_rs[metric_name]\n",
    "    plot_taus(combined_rs, combined_taus, \"Combined (%s)\" % metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
