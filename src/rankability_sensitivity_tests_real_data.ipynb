{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rankability-Sensitivity Tests (Real Data)\n",
    "This notebook executes tests to measure the sensitivity of certain ranking methods to small perturbations in the data. It collects many datapoints about each input matrix and saves the entire dataset into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "from sensitivity_tests import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "from gurobipy import *\n",
    "setParam(\"OutputFlag\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 nfl_data/nfl2008_afc\n"
     ]
    }
   ],
   "source": [
    "directories = [\"nfl_data\", \"lolib_data\"]\n",
    "additional_files = []\n",
    "\n",
    "files = []\n",
    "for directory in directories:\n",
    "    files.extend([join(directory, f) for f in os.listdir(directory) if os.path.isfile(join(directory, f)) and not f.endswith(\".md\")])\n",
    "files.extend(additional_files)\n",
    "print(len(files), files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILENAME = \"sensitivity_dataset_real.csv\"\n",
    "def write_chunk(dataset):\n",
    "    if dataset == []:\n",
    "        return\n",
    "    df = pd.DataFrame(dataset)\n",
    "    if not os.path.isfile(CSV_FILENAME):\n",
    "        df.to_csv(CSV_FILENAME, mode='a', index=False)\n",
    "    elif len(df.columns) != len(pd.read_csv(CSV_FILENAME, nrows=1).columns):\n",
    "        raise Exception(\"Columns do not match!! Dataframe has \" +\n",
    "                        str(len(df.columns)) + \" columns. CSV file has \" +\n",
    "                        str(len(pd.read_csv(CSV_FILENAME, nrows=1).columns)) + \" columns.\")\n",
    "    else:\n",
    "        target_columns = list(pd.read_csv(CSV_FILENAME, nrows=1).columns)\n",
    "        source_columns = df.columns\n",
    "        if not all([(col in target_columns) for col in source_columns]):\n",
    "            raise Exception(\"Columns of dataframe and csv file do not match!!\")\n",
    "        df[target_columns].to_csv(CSV_FILENAME, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl_data/nfl2008_afc running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/97 [00:44<1:11:26, 44.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl_data/nfl2018_nfc running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/97 [00:51<52:37, 33.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl_data/nfl2009_nfc running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/97 [00:56<39:04, 24.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl_data/nfl1994_afc running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/97 [01:27<41:09, 26.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl_data/nfl2018_afc running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/97 [02:12<49:08, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl_data/nfl2003_afc running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/97 [02:55<53:52, 35.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl_data/nfl2014_afc running\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "instances_per_chunk = 1\n",
    "n_trials = 50\n",
    "n_restarts = 50\n",
    "instance_idx = 0\n",
    "\n",
    "for filepath in tqdm(files):\n",
    "    data_source = LOLib(filepath, full_path=True)\n",
    "    if data_source.get_n() > 50:\n",
    "        print(filepath + \" skipped\", flush=True)\n",
    "        continue\n",
    "    print(filepath + \" running\", flush=True)\n",
    "    dataset.append(ProblemInstance(data_source).collect_data(num_random_restarts=n_restarts,n_sensitivity_trials=n_trials))\n",
    "    if (instance_idx + 1) % instances_per_chunk == 0:\n",
    "        write_chunk(dataset)\n",
    "        dataset = []\n",
    "    instance_idx += 1\n",
    "write_chunk(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_FILENAME)\n",
    "sensitivities = [col for col in df.columns if \"mean_sensitivity\" in col]\n",
    "sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"overall_mean_sensitivity\"] = df[sensitivities].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(\"p_lowerbound\", \"overall_mean_sensitivity\", title=\"Sensitivity by p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(\"kendall_w\", \"overall_mean_sensitivity\", title=\"Sensitivity by Kendall W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(\"max_L2_dist\", \"overall_mean_sensitivity\", title=\"Sensitivity by Max L2 Dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(\"mean_L2_dist\", \"overall_mean_sensitivity\", title=\"Sensitivity by Mean L2 Dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(\"min_tau\", \"overall_mean_sensitivity\", title=\"Sensitivity by Min Tau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(\"mean_tau\", \"overall_mean_sensitivity\", title=\"Sensitivity by Mean Tau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_taus(rankability_vals, taus, method_name, scatter_alpha=0.01, histogram_bins=30, save_dir=\"rankability_figures_run5\"):\n",
    "    # Create directory for saving if specified\n",
    "    saving = False\n",
    "    if save_dir is not None and save_dir != \"\":\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        saving = True\n",
    "    \n",
    "    # Plot scatter plot\n",
    "    plt.scatter(rankability_vals, taus, alpha=scatter_alpha)\n",
    "    title = \"%s Sensitivity Scatter\" % method_name\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Rankability')\n",
    "    plt.xlim(0.0, 1.0)\n",
    "    plt.ylabel('Tau')\n",
    "    plt.ylim(-1.0, 1.0)\n",
    "    if saving:\n",
    "        save_path = os.path.join(save_dir, title.replace(\" \", \"_\") + \".png\")\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 2D Histogram\n",
    "    plt.hist2d(rankability_vals, taus, bins=histogram_bins, range=[[0.0, 1.0], [-1.0, 1.0]])\n",
    "    title = \"%s Sensitivity Histogram\" % method_name\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Rankability')\n",
    "    plt.ylabel('Tau')\n",
    "    if saving:\n",
    "        save_path = os.path.join(save_dir, title.replace(\" \", \"_\") + \".png\")\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
