{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping NFL Data from MasseyRatings.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS = [\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2019\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2018\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2017\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2016\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2015\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2014\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2013\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2012\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2011\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2010\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2009\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2008\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2007\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2006\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2005\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2004\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2003\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2002\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2001\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl2000\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1999\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1998\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1997\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1996\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1995\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1994\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1993\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1992\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1991\",\n",
    "    \"https://www.masseyratings.com/scores.php?s=nfl1990\"\n",
    "]\n",
    "base = \"https://www.masseyratings.com/\"\n",
    "ending = \"&all=1&format=1\"\n",
    "output_folder = \"nfl_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_D(raw):\n",
    "    data = np.array([[int(entry) for entry in line] for line in [[wd.strip() for wd in line.split(\",\")] for line in raw][:-1]])[:,[2,4,5,7]]\n",
    "    data[:,0] -= 1\n",
    "    data[:,2] -= 1\n",
    "    n = np.amax(data[:,[0,2]])+1\n",
    "    D = np.zeros(shape=(n,n), dtype=int)\n",
    "    for game in data:\n",
    "        team1,score1,team2,score2 = game\n",
    "        D[team1,team2] += score1-score2\n",
    "    return D\n",
    "\n",
    "def save_D(D, fname):\n",
    "    n = D.shape[0]\n",
    "    with open(fname, \"w\") as fout:\n",
    "        fout.write(str(n) + \"\\n\")\n",
    "        for row in D:\n",
    "            line = \"\"\n",
    "            for elem in row:\n",
    "                line += \" \" + str(elem)\n",
    "            fout.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scraping NFL data\n",
    "for url in URLS:\n",
    "    url_category = url.split(\"=\")[-1]\n",
    "    soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "    links = soup.html.body.find_all('a')\n",
    "    # Scrape NFC\n",
    "    page = requests.get(base + links[2][\"href\"] + ending)\n",
    "    raw_lines = str(BeautifulSoup(page.content, 'html.parser')).split(\"\\n\")\n",
    "    D = create_D(raw_lines)\n",
    "    save_D(D, output_folder + url_category + \"_nfc\")\n",
    "    # Scrape AFC\n",
    "    page = requests.get(base + links[3][\"href\"] + ending)\n",
    "    raw_lines = str(BeautifulSoup(page.content, 'html.parser')).split(\"\\n\")\n",
    "    D = create_D(raw_lines)\n",
    "    save_D(D, output_folder + url_category + \"_afc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
